{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Springboard Data Science Track Capstone Project 2\n",
    "### Music Genre Classification from Audio Samples\n",
    "### by Morgan Fry\n",
    "### Extended Modeling -- Time Distributed CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "#import keras\n",
    "#from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape, Dropout\n",
    "#from keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('no gpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = pd.read_csv('data/features.csv', index_col=0, header=[0, 1, 2])\n",
    "fma_single = pickle.load(open(\"saved/fma_single.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_multi=pickle.load(open(\"saved/fma_multi.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>filepath</th>\n",
       "      <th>genre_top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>data/fma_large/000/000002.mp3</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>data/fma_large/000/000003.mp3</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>data/fma_large/000/000005.mp3</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>data/fma_large/000/000010.mp3</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>data/fma_large/000/000134.mp3</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155315</th>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>data/fma_large/155/155315.mp3</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155316</th>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>data/fma_large/155/155316.mp3</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155317</th>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>data/fma_large/155/155317.mp3</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155318</th>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>data/fma_large/155/155318.mp3</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155319</th>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>data/fma_large/155/155319.mp3</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49537 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             split  subset                       filepath genre_top\n",
       "track_id                                                           \n",
       "2         training   small  data/fma_large/000/000002.mp3   Hip-Hop\n",
       "3         training  medium  data/fma_large/000/000003.mp3   Hip-Hop\n",
       "5         training   small  data/fma_large/000/000005.mp3   Hip-Hop\n",
       "10        training   small  data/fma_large/000/000010.mp3       Pop\n",
       "134       training  medium  data/fma_large/000/000134.mp3   Hip-Hop\n",
       "...            ...     ...                            ...       ...\n",
       "155315    training   large  data/fma_large/155/155315.mp3      Rock\n",
       "155316    training   large  data/fma_large/155/155316.mp3      Rock\n",
       "155317    training   large  data/fma_large/155/155317.mp3      Rock\n",
       "155318    training   large  data/fma_large/155/155318.mp3      Rock\n",
       "155319    training   large  data/fma_large/155/155319.mp3      Rock\n",
       "\n",
       "[49537 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fma_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline model we are going to use the 'small' set of 8000 tracks in 8 classes, and train the model on the mfccs of the tracks which we extracted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mfccs\n",
    "mfcc_df=pickle.load(open(\"saved/mfcc_small.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7997, 23232)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23222</th>\n",
       "      <th>23223</th>\n",
       "      <th>23224</th>\n",
       "      <th>23225</th>\n",
       "      <th>23226</th>\n",
       "      <th>23227</th>\n",
       "      <th>23228</th>\n",
       "      <th>23229</th>\n",
       "      <th>23230</th>\n",
       "      <th>23231</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-299.542053</td>\n",
       "      <td>-202.513412</td>\n",
       "      <td>-159.976059</td>\n",
       "      <td>-115.456413</td>\n",
       "      <td>-80.415161</td>\n",
       "      <td>-67.523239</td>\n",
       "      <td>-57.689404</td>\n",
       "      <td>-65.464790</td>\n",
       "      <td>-84.703659</td>\n",
       "      <td>-96.179939</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.861199</td>\n",
       "      <td>-4.460218</td>\n",
       "      <td>-6.887738</td>\n",
       "      <td>-7.665272</td>\n",
       "      <td>6.717929</td>\n",
       "      <td>12.769140</td>\n",
       "      <td>11.439809</td>\n",
       "      <td>9.167293</td>\n",
       "      <td>7.916427</td>\n",
       "      <td>5.665779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-324.059723</td>\n",
       "      <td>-227.421249</td>\n",
       "      <td>-186.883606</td>\n",
       "      <td>-158.489868</td>\n",
       "      <td>-94.902466</td>\n",
       "      <td>-95.517578</td>\n",
       "      <td>-106.146324</td>\n",
       "      <td>-70.498611</td>\n",
       "      <td>-45.091522</td>\n",
       "      <td>-41.156029</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.403229</td>\n",
       "      <td>-4.675876</td>\n",
       "      <td>5.932048</td>\n",
       "      <td>19.163589</td>\n",
       "      <td>24.138350</td>\n",
       "      <td>12.146925</td>\n",
       "      <td>1.931949</td>\n",
       "      <td>-0.370714</td>\n",
       "      <td>1.137535</td>\n",
       "      <td>-0.625799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-71.376122</td>\n",
       "      <td>-32.296730</td>\n",
       "      <td>-29.356266</td>\n",
       "      <td>-38.037708</td>\n",
       "      <td>-44.881695</td>\n",
       "      <td>-45.910717</td>\n",
       "      <td>-31.081173</td>\n",
       "      <td>8.275231</td>\n",
       "      <td>28.077381</td>\n",
       "      <td>6.006516</td>\n",
       "      <td>...</td>\n",
       "      <td>9.814901</td>\n",
       "      <td>0.409050</td>\n",
       "      <td>-6.546686</td>\n",
       "      <td>-4.728213</td>\n",
       "      <td>-2.329597</td>\n",
       "      <td>4.121199</td>\n",
       "      <td>8.337200</td>\n",
       "      <td>8.429386</td>\n",
       "      <td>10.133602</td>\n",
       "      <td>11.033691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-561.324280</td>\n",
       "      <td>-523.545837</td>\n",
       "      <td>-449.814423</td>\n",
       "      <td>-342.445557</td>\n",
       "      <td>-306.727356</td>\n",
       "      <td>-308.809631</td>\n",
       "      <td>-307.733276</td>\n",
       "      <td>-317.345245</td>\n",
       "      <td>-362.774811</td>\n",
       "      <td>-419.306946</td>\n",
       "      <td>...</td>\n",
       "      <td>1.818927</td>\n",
       "      <td>3.912658</td>\n",
       "      <td>4.593844</td>\n",
       "      <td>2.139801</td>\n",
       "      <td>-4.394735</td>\n",
       "      <td>-5.267244</td>\n",
       "      <td>-6.697974</td>\n",
       "      <td>-5.783470</td>\n",
       "      <td>-5.886441</td>\n",
       "      <td>-3.706590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-464.980743</td>\n",
       "      <td>-371.434326</td>\n",
       "      <td>-330.917175</td>\n",
       "      <td>-342.813904</td>\n",
       "      <td>-362.013550</td>\n",
       "      <td>-368.364441</td>\n",
       "      <td>-361.755188</td>\n",
       "      <td>-358.438049</td>\n",
       "      <td>-365.668640</td>\n",
       "      <td>-375.685730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601643</td>\n",
       "      <td>-0.995060</td>\n",
       "      <td>0.146230</td>\n",
       "      <td>3.676285</td>\n",
       "      <td>-1.177926</td>\n",
       "      <td>-2.822582</td>\n",
       "      <td>4.884428</td>\n",
       "      <td>3.736303</td>\n",
       "      <td>2.701882</td>\n",
       "      <td>-2.805002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1           2           3           4           5      \\\n",
       "2   -299.542053 -202.513412 -159.976059 -115.456413  -80.415161  -67.523239   \n",
       "5   -324.059723 -227.421249 -186.883606 -158.489868  -94.902466  -95.517578   \n",
       "10   -71.376122  -32.296730  -29.356266  -38.037708  -44.881695  -45.910717   \n",
       "140 -561.324280 -523.545837 -449.814423 -342.445557 -306.727356 -308.809631   \n",
       "141 -464.980743 -371.434326 -330.917175 -342.813904 -362.013550 -368.364441   \n",
       "\n",
       "          6           7           8           9      ...     23222     23223  \\\n",
       "2    -57.689404  -65.464790  -84.703659  -96.179939  ... -5.861199 -4.460218   \n",
       "5   -106.146324  -70.498611  -45.091522  -41.156029  ... -6.403229 -4.675876   \n",
       "10   -31.081173    8.275231   28.077381    6.006516  ...  9.814901  0.409050   \n",
       "140 -307.733276 -317.345245 -362.774811 -419.306946  ...  1.818927  3.912658   \n",
       "141 -361.755188 -358.438049 -365.668640 -375.685730  ...  0.601643 -0.995060   \n",
       "\n",
       "        23224      23225      23226      23227      23228     23229  \\\n",
       "2   -6.887738  -7.665272   6.717929  12.769140  11.439809  9.167293   \n",
       "5    5.932048  19.163589  24.138350  12.146925   1.931949 -0.370714   \n",
       "10  -6.546686  -4.728213  -2.329597   4.121199   8.337200  8.429386   \n",
       "140  4.593844   2.139801  -4.394735  -5.267244  -6.697974 -5.783470   \n",
       "141  0.146230   3.676285  -1.177926  -2.822582   4.884428  3.736303   \n",
       "\n",
       "         23230      23231  \n",
       "2     7.916427   5.665779  \n",
       "5     1.137535  -0.625799  \n",
       "10   10.133602  11.033691  \n",
       "140  -5.886441  -3.706590  \n",
       "141   2.701882  -2.805002  \n",
       "\n",
       "[5 rows x 23232 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23222</th>\n",
       "      <th>23223</th>\n",
       "      <th>23224</th>\n",
       "      <th>23225</th>\n",
       "      <th>23226</th>\n",
       "      <th>23227</th>\n",
       "      <th>23228</th>\n",
       "      <th>23229</th>\n",
       "      <th>23230</th>\n",
       "      <th>23231</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-299.542053</td>\n",
       "      <td>-202.513412</td>\n",
       "      <td>-159.976059</td>\n",
       "      <td>-115.456413</td>\n",
       "      <td>-80.415161</td>\n",
       "      <td>-67.523239</td>\n",
       "      <td>-57.689404</td>\n",
       "      <td>-65.464790</td>\n",
       "      <td>-84.703659</td>\n",
       "      <td>-96.179939</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.861199</td>\n",
       "      <td>-4.460218</td>\n",
       "      <td>-6.887738</td>\n",
       "      <td>-7.665272</td>\n",
       "      <td>6.717929</td>\n",
       "      <td>12.769140</td>\n",
       "      <td>11.439809</td>\n",
       "      <td>9.167293</td>\n",
       "      <td>7.916427</td>\n",
       "      <td>5.665779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-324.059723</td>\n",
       "      <td>-227.421249</td>\n",
       "      <td>-186.883606</td>\n",
       "      <td>-158.489868</td>\n",
       "      <td>-94.902466</td>\n",
       "      <td>-95.517578</td>\n",
       "      <td>-106.146324</td>\n",
       "      <td>-70.498611</td>\n",
       "      <td>-45.091522</td>\n",
       "      <td>-41.156029</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.403229</td>\n",
       "      <td>-4.675876</td>\n",
       "      <td>5.932048</td>\n",
       "      <td>19.163589</td>\n",
       "      <td>24.138350</td>\n",
       "      <td>12.146925</td>\n",
       "      <td>1.931949</td>\n",
       "      <td>-0.370714</td>\n",
       "      <td>1.137535</td>\n",
       "      <td>-0.625799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-71.376122</td>\n",
       "      <td>-32.296730</td>\n",
       "      <td>-29.356266</td>\n",
       "      <td>-38.037708</td>\n",
       "      <td>-44.881695</td>\n",
       "      <td>-45.910717</td>\n",
       "      <td>-31.081173</td>\n",
       "      <td>8.275231</td>\n",
       "      <td>28.077381</td>\n",
       "      <td>6.006516</td>\n",
       "      <td>...</td>\n",
       "      <td>9.814901</td>\n",
       "      <td>0.409050</td>\n",
       "      <td>-6.546686</td>\n",
       "      <td>-4.728213</td>\n",
       "      <td>-2.329597</td>\n",
       "      <td>4.121199</td>\n",
       "      <td>8.337200</td>\n",
       "      <td>8.429386</td>\n",
       "      <td>10.133602</td>\n",
       "      <td>11.033691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-561.324280</td>\n",
       "      <td>-523.545837</td>\n",
       "      <td>-449.814423</td>\n",
       "      <td>-342.445557</td>\n",
       "      <td>-306.727356</td>\n",
       "      <td>-308.809631</td>\n",
       "      <td>-307.733276</td>\n",
       "      <td>-317.345245</td>\n",
       "      <td>-362.774811</td>\n",
       "      <td>-419.306946</td>\n",
       "      <td>...</td>\n",
       "      <td>1.818927</td>\n",
       "      <td>3.912658</td>\n",
       "      <td>4.593844</td>\n",
       "      <td>2.139801</td>\n",
       "      <td>-4.394735</td>\n",
       "      <td>-5.267244</td>\n",
       "      <td>-6.697974</td>\n",
       "      <td>-5.783470</td>\n",
       "      <td>-5.886441</td>\n",
       "      <td>-3.706590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-464.980743</td>\n",
       "      <td>-371.434326</td>\n",
       "      <td>-330.917175</td>\n",
       "      <td>-342.813904</td>\n",
       "      <td>-362.013550</td>\n",
       "      <td>-368.364441</td>\n",
       "      <td>-361.755188</td>\n",
       "      <td>-358.438049</td>\n",
       "      <td>-365.668640</td>\n",
       "      <td>-375.685730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601643</td>\n",
       "      <td>-0.995060</td>\n",
       "      <td>0.146230</td>\n",
       "      <td>3.676285</td>\n",
       "      <td>-1.177926</td>\n",
       "      <td>-2.822582</td>\n",
       "      <td>4.884428</td>\n",
       "      <td>3.736303</td>\n",
       "      <td>2.701882</td>\n",
       "      <td>-2.805002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154308</th>\n",
       "      <td>-313.429077</td>\n",
       "      <td>-285.330048</td>\n",
       "      <td>-283.423401</td>\n",
       "      <td>-287.088348</td>\n",
       "      <td>-289.263672</td>\n",
       "      <td>-184.150192</td>\n",
       "      <td>-41.746201</td>\n",
       "      <td>-12.892635</td>\n",
       "      <td>-55.076210</td>\n",
       "      <td>-115.045479</td>\n",
       "      <td>...</td>\n",
       "      <td>10.231204</td>\n",
       "      <td>11.211655</td>\n",
       "      <td>0.058539</td>\n",
       "      <td>-11.264427</td>\n",
       "      <td>-6.596434</td>\n",
       "      <td>4.120525</td>\n",
       "      <td>6.856134</td>\n",
       "      <td>5.343898</td>\n",
       "      <td>2.773130</td>\n",
       "      <td>1.698187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154309</th>\n",
       "      <td>-486.301819</td>\n",
       "      <td>-482.713928</td>\n",
       "      <td>-496.109802</td>\n",
       "      <td>-501.279755</td>\n",
       "      <td>-502.606598</td>\n",
       "      <td>-506.784668</td>\n",
       "      <td>-509.464905</td>\n",
       "      <td>-310.994598</td>\n",
       "      <td>-145.997116</td>\n",
       "      <td>-127.237030</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.249464</td>\n",
       "      <td>-10.734337</td>\n",
       "      <td>-11.473764</td>\n",
       "      <td>-8.660153</td>\n",
       "      <td>-7.335606</td>\n",
       "      <td>-11.601185</td>\n",
       "      <td>-16.454685</td>\n",
       "      <td>-15.517137</td>\n",
       "      <td>-11.830728</td>\n",
       "      <td>-11.240954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154413</th>\n",
       "      <td>-155.809250</td>\n",
       "      <td>-137.494919</td>\n",
       "      <td>-114.974205</td>\n",
       "      <td>-140.923645</td>\n",
       "      <td>-162.126450</td>\n",
       "      <td>-160.300812</td>\n",
       "      <td>-160.252792</td>\n",
       "      <td>-164.502640</td>\n",
       "      <td>-163.036118</td>\n",
       "      <td>-166.671722</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.811752</td>\n",
       "      <td>-17.902248</td>\n",
       "      <td>-22.706905</td>\n",
       "      <td>-22.197693</td>\n",
       "      <td>-24.581553</td>\n",
       "      <td>-25.488754</td>\n",
       "      <td>-21.233810</td>\n",
       "      <td>-23.033970</td>\n",
       "      <td>-21.506649</td>\n",
       "      <td>-22.316118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154414</th>\n",
       "      <td>-157.556030</td>\n",
       "      <td>-162.392120</td>\n",
       "      <td>-172.492035</td>\n",
       "      <td>-185.008377</td>\n",
       "      <td>-195.222931</td>\n",
       "      <td>-197.421844</td>\n",
       "      <td>-194.316422</td>\n",
       "      <td>-151.761810</td>\n",
       "      <td>-53.744122</td>\n",
       "      <td>0.694292</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.949778</td>\n",
       "      <td>-13.652007</td>\n",
       "      <td>-14.656978</td>\n",
       "      <td>-12.779702</td>\n",
       "      <td>-15.503021</td>\n",
       "      <td>-17.758909</td>\n",
       "      <td>-18.673512</td>\n",
       "      <td>-14.957970</td>\n",
       "      <td>-11.633366</td>\n",
       "      <td>-14.272188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155066</th>\n",
       "      <td>-239.451935</td>\n",
       "      <td>-245.493454</td>\n",
       "      <td>-252.646561</td>\n",
       "      <td>-198.174835</td>\n",
       "      <td>-176.131500</td>\n",
       "      <td>-206.888504</td>\n",
       "      <td>-248.449234</td>\n",
       "      <td>-260.804413</td>\n",
       "      <td>-262.628052</td>\n",
       "      <td>-267.949860</td>\n",
       "      <td>...</td>\n",
       "      <td>8.492558</td>\n",
       "      <td>7.201674</td>\n",
       "      <td>8.079520</td>\n",
       "      <td>15.428879</td>\n",
       "      <td>19.309864</td>\n",
       "      <td>18.128532</td>\n",
       "      <td>8.843944</td>\n",
       "      <td>6.262315</td>\n",
       "      <td>9.994928</td>\n",
       "      <td>12.015592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7997 rows Ã— 23232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1           2           3           4      \\\n",
       "2      -299.542053 -202.513412 -159.976059 -115.456413  -80.415161   \n",
       "5      -324.059723 -227.421249 -186.883606 -158.489868  -94.902466   \n",
       "10      -71.376122  -32.296730  -29.356266  -38.037708  -44.881695   \n",
       "140    -561.324280 -523.545837 -449.814423 -342.445557 -306.727356   \n",
       "141    -464.980743 -371.434326 -330.917175 -342.813904 -362.013550   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "154308 -313.429077 -285.330048 -283.423401 -287.088348 -289.263672   \n",
       "154309 -486.301819 -482.713928 -496.109802 -501.279755 -502.606598   \n",
       "154413 -155.809250 -137.494919 -114.974205 -140.923645 -162.126450   \n",
       "154414 -157.556030 -162.392120 -172.492035 -185.008377 -195.222931   \n",
       "155066 -239.451935 -245.493454 -252.646561 -198.174835 -176.131500   \n",
       "\n",
       "             5           6           7           8           9      ...  \\\n",
       "2       -67.523239  -57.689404  -65.464790  -84.703659  -96.179939  ...   \n",
       "5       -95.517578 -106.146324  -70.498611  -45.091522  -41.156029  ...   \n",
       "10      -45.910717  -31.081173    8.275231   28.077381    6.006516  ...   \n",
       "140    -308.809631 -307.733276 -317.345245 -362.774811 -419.306946  ...   \n",
       "141    -368.364441 -361.755188 -358.438049 -365.668640 -375.685730  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "154308 -184.150192  -41.746201  -12.892635  -55.076210 -115.045479  ...   \n",
       "154309 -506.784668 -509.464905 -310.994598 -145.997116 -127.237030  ...   \n",
       "154413 -160.300812 -160.252792 -164.502640 -163.036118 -166.671722  ...   \n",
       "154414 -197.421844 -194.316422 -151.761810  -53.744122    0.694292  ...   \n",
       "155066 -206.888504 -248.449234 -260.804413 -262.628052 -267.949860  ...   \n",
       "\n",
       "            23222      23223      23224      23225      23226      23227  \\\n",
       "2       -5.861199  -4.460218  -6.887738  -7.665272   6.717929  12.769140   \n",
       "5       -6.403229  -4.675876   5.932048  19.163589  24.138350  12.146925   \n",
       "10       9.814901   0.409050  -6.546686  -4.728213  -2.329597   4.121199   \n",
       "140      1.818927   3.912658   4.593844   2.139801  -4.394735  -5.267244   \n",
       "141      0.601643  -0.995060   0.146230   3.676285  -1.177926  -2.822582   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "154308  10.231204  11.211655   0.058539 -11.264427  -6.596434   4.120525   \n",
       "154309  -3.249464 -10.734337 -11.473764  -8.660153  -7.335606 -11.601185   \n",
       "154413 -16.811752 -17.902248 -22.706905 -22.197693 -24.581553 -25.488754   \n",
       "154414 -14.949778 -13.652007 -14.656978 -12.779702 -15.503021 -17.758909   \n",
       "155066   8.492558   7.201674   8.079520  15.428879  19.309864  18.128532   \n",
       "\n",
       "            23228      23229      23230      23231  \n",
       "2       11.439809   9.167293   7.916427   5.665779  \n",
       "5        1.931949  -0.370714   1.137535  -0.625799  \n",
       "10       8.337200   8.429386  10.133602  11.033691  \n",
       "140     -6.697974  -5.783470  -5.886441  -3.706590  \n",
       "141      4.884428   3.736303   2.701882  -2.805002  \n",
       "...           ...        ...        ...        ...  \n",
       "154308   6.856134   5.343898   2.773130   1.698187  \n",
       "154309 -16.454685 -15.517137 -11.830728 -11.240954  \n",
       "154413 -21.233810 -23.033970 -21.506649 -22.316118  \n",
       "154414 -18.673512 -14.957970 -11.633366 -14.272188  \n",
       "155066   8.843944   6.262315   9.994928  12.015592  \n",
       "\n",
       "[7997 rows x 23232 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_df.fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the 8000 track balanced subset for baseline modeling\n",
    "\n",
    "drop3=pickle.load(open(\"saved/drop3.p\",\"rb\"))\n",
    "fma_single.drop(drop3, inplace=True)\n",
    "subset = fma_single.index[fma_single['subset'] == 'small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fma_small=fma_single.loc[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_sub=mfcc_df.loc[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the built in train/test/validation split in case we want to compare to other models over this dataset\n",
    "train = fma_small.index[fma_small['split'] == 'training']\n",
    "val = fma_small.index[fma_small['split'] == 'validation']\n",
    "test = fma_small.index[fma_small['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6310 793 794\n"
     ]
    }
   ],
   "source": [
    "print(len(train),len(val),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing single label\n",
    "\n",
    "#enc=MultiLabelBinarizer()\n",
    "enc=LabelEncoder()\n",
    "labels=fma_small['genre_top']\n",
    "#labels=y_df\n",
    "\n",
    "# Split in training, validation and testing sets.\n",
    "\n",
    "#single label\n",
    "y_train = enc.fit_transform(labels[train])\n",
    "y_val = enc.transform(labels[val])\n",
    "y_test = enc.transform(labels[test])\n",
    "#y_train = track_sub['label']\n",
    "\n",
    "X_train = mfcc_sub.loc[train].values\n",
    "X_val = mfcc_sub.loc[val].values\n",
    "X_test = mfcc_sub.loc[test].values\n",
    "    \n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler(copy=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6310, 23232)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 968, 24, 1)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 968, 22, 64)       256       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 968, 11, 64)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 968, 9, 128)       24704     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 968, 7, 128)       49280     \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 968, 3, 128)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 968, 384)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                114944    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 198,536\n",
      "Trainable params: 198,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "#define CNN-LSTM\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Reshape((968,24,1),input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.TimeDistributed(layers.Conv1D(64, 3, activation='relu')))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling1D(2)))\n",
    "model.add(layers.TimeDistributed(layers.Conv1D(128, 3, activation='relu')))\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Conv1D(128, 3, activation='relu')))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling1D(2)))\n",
    "model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "\n",
    "model.add(layers.LSTM(units=64, dropout=0.2, return_sequences=False))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.001, nesterov=True)\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "395/395 [==============================] - 49s 124ms/step - loss: 2.0773 - accuracy: 0.1326 - val_loss: 2.0697 - val_accuracy: 0.1753\n",
      "Epoch 2/500\n",
      "395/395 [==============================] - 47s 119ms/step - loss: 2.0652 - accuracy: 0.1621 - val_loss: 2.0562 - val_accuracy: 0.2055\n",
      "Epoch 3/500\n",
      "395/395 [==============================] - 47s 119ms/step - loss: 2.0529 - accuracy: 0.1780 - val_loss: 2.0411 - val_accuracy: 0.2068\n",
      "Epoch 4/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 2.0372 - accuracy: 0.1843 - val_loss: 2.0277 - val_accuracy: 0.2156\n",
      "Epoch 5/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 2.0277 - accuracy: 0.1823 - val_loss: 2.0187 - val_accuracy: 0.1980\n",
      "Epoch 6/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 2.0197 - accuracy: 0.1921 - val_loss: 2.0119 - val_accuracy: 0.1980\n",
      "Epoch 7/500\n",
      "395/395 [==============================] - 49s 123ms/step - loss: 2.0080 - accuracy: 0.2006 - val_loss: 2.0017 - val_accuracy: 0.2043\n",
      "Epoch 8/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9920 - accuracy: 0.1995 - val_loss: 1.9778 - val_accuracy: 0.2207\n",
      "Epoch 9/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.9764 - accuracy: 0.2117 - val_loss: 1.9972 - val_accuracy: 0.2119\n",
      "Epoch 10/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9691 - accuracy: 0.2106 - val_loss: 2.0097 - val_accuracy: 0.2106\n",
      "Epoch 11/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9552 - accuracy: 0.2282 - val_loss: 1.9494 - val_accuracy: 0.2295\n",
      "Epoch 12/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9417 - accuracy: 0.2287 - val_loss: 2.0253 - val_accuracy: 0.1967\n",
      "Epoch 13/500\n",
      "395/395 [==============================] - 50s 126ms/step - loss: 1.9376 - accuracy: 0.2391 - val_loss: 1.9338 - val_accuracy: 0.2573\n",
      "Epoch 14/500\n",
      "395/395 [==============================] - 50s 126ms/step - loss: 1.9228 - accuracy: 0.2532 - val_loss: 2.0237 - val_accuracy: 0.2245\n",
      "Epoch 15/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9201 - accuracy: 0.2523 - val_loss: 1.8992 - val_accuracy: 0.2787\n",
      "Epoch 16/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.9026 - accuracy: 0.2559 - val_loss: 1.8416 - val_accuracy: 0.3064\n",
      "Epoch 17/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.9370 - accuracy: 0.2479 - val_loss: 1.8487 - val_accuracy: 0.3039\n",
      "Epoch 18/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.8994 - accuracy: 0.2664 - val_loss: 1.8551 - val_accuracy: 0.2913\n",
      "Epoch 19/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.9267 - accuracy: 0.2580 - val_loss: 1.8476 - val_accuracy: 0.3039\n",
      "Epoch 20/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 2.0348 - accuracy: 0.1783 - val_loss: 2.0071 - val_accuracy: 0.2005\n",
      "Epoch 21/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 2.0081 - accuracy: 0.1903 - val_loss: 1.9824 - val_accuracy: 0.2308\n",
      "Epoch 22/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.9916 - accuracy: 0.2027 - val_loss: 1.9661 - val_accuracy: 0.2295\n",
      "Epoch 23/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.9715 - accuracy: 0.2211 - val_loss: 1.9780 - val_accuracy: 0.2257\n",
      "Epoch 24/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.9607 - accuracy: 0.2274 - val_loss: 1.9253 - val_accuracy: 0.2434\n",
      "Epoch 25/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.9461 - accuracy: 0.2350 - val_loss: 1.9202 - val_accuracy: 0.2497\n",
      "Epoch 26/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.9347 - accuracy: 0.2452 - val_loss: 1.9273 - val_accuracy: 0.2459\n",
      "Epoch 27/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9245 - accuracy: 0.2382 - val_loss: 1.8735 - val_accuracy: 0.2787\n",
      "Epoch 28/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.9069 - accuracy: 0.2637 - val_loss: 1.8745 - val_accuracy: 0.2938\n",
      "Epoch 29/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.8894 - accuracy: 0.2689 - val_loss: 1.8640 - val_accuracy: 0.2863\n",
      "Epoch 30/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.9051 - accuracy: 0.2620 - val_loss: 1.8369 - val_accuracy: 0.3216\n",
      "Epoch 31/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.8826 - accuracy: 0.2811 - val_loss: 1.8896 - val_accuracy: 0.2787\n",
      "Epoch 32/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.8582 - accuracy: 0.2883 - val_loss: 1.8075 - val_accuracy: 0.3014\n",
      "Epoch 33/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.8586 - accuracy: 0.2899 - val_loss: 1.7624 - val_accuracy: 0.3392\n",
      "Epoch 34/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.8532 - accuracy: 0.2918 - val_loss: 1.8140 - val_accuracy: 0.2913\n",
      "Epoch 35/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.8644 - accuracy: 0.2784 - val_loss: 1.8132 - val_accuracy: 0.3039\n",
      "Epoch 36/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.8403 - accuracy: 0.3059 - val_loss: 1.7763 - val_accuracy: 0.3304\n",
      "Epoch 37/500\n",
      "395/395 [==============================] - 49s 123ms/step - loss: 1.8568 - accuracy: 0.2978 - val_loss: 1.7781 - val_accuracy: 0.3279\n",
      "Epoch 38/500\n",
      "395/395 [==============================] - 49s 124ms/step - loss: 1.8322 - accuracy: 0.3086 - val_loss: 1.8235 - val_accuracy: 0.3115\n",
      "Epoch 39/500\n",
      "395/395 [==============================] - 49s 124ms/step - loss: 1.8431 - accuracy: 0.3005 - val_loss: 1.7848 - val_accuracy: 0.3279\n",
      "Epoch 40/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9540 - accuracy: 0.2498 - val_loss: 1.9461 - val_accuracy: 0.2522\n",
      "Epoch 41/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9208 - accuracy: 0.2515 - val_loss: 1.8022 - val_accuracy: 0.3279\n",
      "Epoch 42/500\n",
      "395/395 [==============================] - 49s 123ms/step - loss: 1.8893 - accuracy: 0.2848 - val_loss: 2.0859 - val_accuracy: 0.1917\n",
      "Epoch 43/500\n",
      "395/395 [==============================] - 49s 124ms/step - loss: 1.8685 - accuracy: 0.2845 - val_loss: 1.7946 - val_accuracy: 0.3291\n",
      "Epoch 44/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.9423 - accuracy: 0.2556 - val_loss: 1.8012 - val_accuracy: 0.3405\n",
      "Epoch 45/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.8371 - accuracy: 0.3078 - val_loss: 1.8068 - val_accuracy: 0.3241\n",
      "Epoch 46/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.8945 - accuracy: 0.2662 - val_loss: 1.7910 - val_accuracy: 0.3405\n",
      "Epoch 47/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.8549 - accuracy: 0.2902 - val_loss: 1.7785 - val_accuracy: 0.3317\n",
      "Epoch 48/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.9248 - accuracy: 0.2693 - val_loss: 2.0961 - val_accuracy: 0.1589\n",
      "Epoch 49/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.9789 - accuracy: 0.2217 - val_loss: 1.9568 - val_accuracy: 0.2207\n",
      "Epoch 50/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.9807 - accuracy: 0.2271 - val_loss: 1.9105 - val_accuracy: 0.2573\n",
      "Epoch 51/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.9653 - accuracy: 0.2372 - val_loss: 1.9181 - val_accuracy: 0.2863\n",
      "Epoch 52/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.9338 - accuracy: 0.2539 - val_loss: 1.8567 - val_accuracy: 0.2976\n",
      "Epoch 53/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.9796 - accuracy: 0.2238 - val_loss: 1.9193 - val_accuracy: 0.2799\n",
      "Epoch 54/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.9164 - accuracy: 0.2471 - val_loss: 1.8793 - val_accuracy: 0.2837\n",
      "Epoch 55/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.8979 - accuracy: 0.2674 - val_loss: 2.0456 - val_accuracy: 0.1841\n",
      "Epoch 56/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.9080 - accuracy: 0.2585 - val_loss: 1.9538 - val_accuracy: 0.2358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.8877 - accuracy: 0.2715 - val_loss: 1.8352 - val_accuracy: 0.2913\n",
      "Epoch 58/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.8522 - accuracy: 0.2856 - val_loss: 1.8047 - val_accuracy: 0.2863\n",
      "Epoch 59/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.8432 - accuracy: 0.2872 - val_loss: 1.7917 - val_accuracy: 0.3279\n",
      "Epoch 60/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.8496 - accuracy: 0.2889 - val_loss: 1.7958 - val_accuracy: 0.3077\n",
      "Epoch 61/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.8308 - accuracy: 0.2976 - val_loss: 2.0149 - val_accuracy: 0.2409\n",
      "Epoch 62/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.8637 - accuracy: 0.2797 - val_loss: 1.8395 - val_accuracy: 0.2863\n",
      "Epoch 63/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.8566 - accuracy: 0.2891 - val_loss: 1.9912 - val_accuracy: 0.2055\n",
      "Epoch 64/500\n",
      "395/395 [==============================] - 40s 102ms/step - loss: 1.8987 - accuracy: 0.2666 - val_loss: 1.8426 - val_accuracy: 0.2888\n",
      "Epoch 65/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.9276 - accuracy: 0.2556 - val_loss: 1.8653 - val_accuracy: 0.2938\n",
      "Epoch 66/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8901 - accuracy: 0.2721 - val_loss: 2.0973 - val_accuracy: 0.1248\n",
      "Epoch 67/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 2.0645 - accuracy: 0.1542 - val_loss: 2.0220 - val_accuracy: 0.2371\n",
      "Epoch 68/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 2.0234 - accuracy: 0.1807 - val_loss: 2.0137 - val_accuracy: 0.1778\n",
      "Epoch 69/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.9846 - accuracy: 0.2116 - val_loss: 1.9567 - val_accuracy: 0.2547\n",
      "Epoch 70/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.9649 - accuracy: 0.2223 - val_loss: 1.9434 - val_accuracy: 0.2219\n",
      "Epoch 71/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.9397 - accuracy: 0.2312 - val_loss: 1.9349 - val_accuracy: 0.2421\n",
      "Epoch 72/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.9287 - accuracy: 0.2368 - val_loss: 1.9265 - val_accuracy: 0.2598\n",
      "Epoch 73/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.9202 - accuracy: 0.2366 - val_loss: 1.9231 - val_accuracy: 0.2585\n",
      "Epoch 74/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.9076 - accuracy: 0.2469 - val_loss: 1.9008 - val_accuracy: 0.2762\n",
      "Epoch 75/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8961 - accuracy: 0.2501 - val_loss: 1.8719 - val_accuracy: 0.2711\n",
      "Epoch 76/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8924 - accuracy: 0.2548 - val_loss: 1.9557 - val_accuracy: 0.2018\n",
      "Epoch 77/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8820 - accuracy: 0.2599 - val_loss: 1.8859 - val_accuracy: 0.2648\n",
      "Epoch 78/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8731 - accuracy: 0.2628 - val_loss: 1.9372 - val_accuracy: 0.2434\n",
      "Epoch 79/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8666 - accuracy: 0.2708 - val_loss: 1.8178 - val_accuracy: 0.3140\n",
      "Epoch 80/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8628 - accuracy: 0.2716 - val_loss: 1.8537 - val_accuracy: 0.3090\n",
      "Epoch 81/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8471 - accuracy: 0.2824 - val_loss: 1.8284 - val_accuracy: 0.3165\n",
      "Epoch 82/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8476 - accuracy: 0.2911 - val_loss: 1.8181 - val_accuracy: 0.3228\n",
      "Epoch 83/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8456 - accuracy: 0.2876 - val_loss: 1.8726 - val_accuracy: 0.2673\n",
      "Epoch 84/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8438 - accuracy: 0.2813 - val_loss: 1.8287 - val_accuracy: 0.3140\n",
      "Epoch 85/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8359 - accuracy: 0.2889 - val_loss: 1.7957 - val_accuracy: 0.3430\n",
      "Epoch 86/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8285 - accuracy: 0.2930 - val_loss: 1.7914 - val_accuracy: 0.3367\n",
      "Epoch 87/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8279 - accuracy: 0.2916 - val_loss: 1.8228 - val_accuracy: 0.3430\n",
      "Epoch 88/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8260 - accuracy: 0.2918 - val_loss: 1.8902 - val_accuracy: 0.2724\n",
      "Epoch 89/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8230 - accuracy: 0.2967 - val_loss: 1.8380 - val_accuracy: 0.3077\n",
      "Epoch 90/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8160 - accuracy: 0.2914 - val_loss: 1.8520 - val_accuracy: 0.3026\n",
      "Epoch 91/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8148 - accuracy: 0.2910 - val_loss: 1.7740 - val_accuracy: 0.3317\n",
      "Epoch 92/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8097 - accuracy: 0.3008 - val_loss: 1.8114 - val_accuracy: 0.3405\n",
      "Epoch 93/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8109 - accuracy: 0.3008 - val_loss: 1.7875 - val_accuracy: 0.3493\n",
      "Epoch 94/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.8075 - accuracy: 0.3014 - val_loss: 1.8843 - val_accuracy: 0.2762\n",
      "Epoch 95/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8039 - accuracy: 0.2973 - val_loss: 1.8602 - val_accuracy: 0.2875\n",
      "Epoch 96/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.8068 - accuracy: 0.3040 - val_loss: 1.7767 - val_accuracy: 0.3329\n",
      "Epoch 97/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7987 - accuracy: 0.3063 - val_loss: 1.8875 - val_accuracy: 0.2573\n",
      "Epoch 98/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7949 - accuracy: 0.3086 - val_loss: 1.7634 - val_accuracy: 0.3518\n",
      "Epoch 99/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7982 - accuracy: 0.3060 - val_loss: 1.7526 - val_accuracy: 0.3241\n",
      "Epoch 100/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7954 - accuracy: 0.3101 - val_loss: 1.8196 - val_accuracy: 0.3266\n",
      "Epoch 101/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7956 - accuracy: 0.3106 - val_loss: 1.7581 - val_accuracy: 0.3670\n",
      "Epoch 102/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7884 - accuracy: 0.3070 - val_loss: 1.8292 - val_accuracy: 0.3203\n",
      "Epoch 103/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7877 - accuracy: 0.3111 - val_loss: 1.7790 - val_accuracy: 0.3304\n",
      "Epoch 104/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7852 - accuracy: 0.3125 - val_loss: 1.7769 - val_accuracy: 0.3329\n",
      "Epoch 105/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7857 - accuracy: 0.3124 - val_loss: 1.7382 - val_accuracy: 0.3506\n",
      "Epoch 106/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7829 - accuracy: 0.3192 - val_loss: 1.7675 - val_accuracy: 0.3367\n",
      "Epoch 107/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7797 - accuracy: 0.3260 - val_loss: 1.7754 - val_accuracy: 0.3329\n",
      "Epoch 108/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7783 - accuracy: 0.3154 - val_loss: 1.7856 - val_accuracy: 0.3090\n",
      "Epoch 109/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7764 - accuracy: 0.3149 - val_loss: 1.7462 - val_accuracy: 0.3216\n",
      "Epoch 110/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7700 - accuracy: 0.3181 - val_loss: 1.7513 - val_accuracy: 0.3203\n",
      "Epoch 111/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7691 - accuracy: 0.3233 - val_loss: 1.7741 - val_accuracy: 0.2976\n",
      "Epoch 112/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7698 - accuracy: 0.3214 - val_loss: 1.7735 - val_accuracy: 0.2976\n",
      "Epoch 113/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7650 - accuracy: 0.3293 - val_loss: 1.8315 - val_accuracy: 0.3052\n",
      "Epoch 114/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7697 - accuracy: 0.3261 - val_loss: 1.7783 - val_accuracy: 0.3266\n",
      "Epoch 115/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7623 - accuracy: 0.3301 - val_loss: 1.7443 - val_accuracy: 0.3342\n",
      "Epoch 116/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7582 - accuracy: 0.3304 - val_loss: 1.7586 - val_accuracy: 0.3190\n",
      "Epoch 117/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7547 - accuracy: 0.3333 - val_loss: 1.7730 - val_accuracy: 0.3165\n",
      "Epoch 118/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7505 - accuracy: 0.3382 - val_loss: 1.8146 - val_accuracy: 0.2799\n",
      "Epoch 119/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7518 - accuracy: 0.3357 - val_loss: 1.7888 - val_accuracy: 0.3102\n",
      "Epoch 120/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7526 - accuracy: 0.3393 - val_loss: 1.7501 - val_accuracy: 0.3279\n",
      "Epoch 121/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7419 - accuracy: 0.3401 - val_loss: 1.7721 - val_accuracy: 0.3039\n",
      "Epoch 122/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7408 - accuracy: 0.3429 - val_loss: 1.7142 - val_accuracy: 0.3657\n",
      "Epoch 123/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7398 - accuracy: 0.3444 - val_loss: 1.7510 - val_accuracy: 0.3518\n",
      "Epoch 124/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7416 - accuracy: 0.3455 - val_loss: 1.7145 - val_accuracy: 0.3279\n",
      "Epoch 125/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7323 - accuracy: 0.3488 - val_loss: 1.7489 - val_accuracy: 0.3480\n",
      "Epoch 126/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7376 - accuracy: 0.3371 - val_loss: 1.7504 - val_accuracy: 0.3392\n",
      "Epoch 127/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7291 - accuracy: 0.3471 - val_loss: 1.7304 - val_accuracy: 0.3455\n",
      "Epoch 128/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7305 - accuracy: 0.3480 - val_loss: 1.7838 - val_accuracy: 0.3178\n",
      "Epoch 129/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7325 - accuracy: 0.3441 - val_loss: 1.6954 - val_accuracy: 0.3871\n",
      "Epoch 130/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7307 - accuracy: 0.3520 - val_loss: 1.6796 - val_accuracy: 0.3707\n",
      "Epoch 131/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7294 - accuracy: 0.3471 - val_loss: 1.6913 - val_accuracy: 0.3770\n",
      "Epoch 132/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7310 - accuracy: 0.3436 - val_loss: 1.6959 - val_accuracy: 0.3657\n",
      "Epoch 133/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7174 - accuracy: 0.3493 - val_loss: 1.6851 - val_accuracy: 0.3783\n",
      "Epoch 134/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7205 - accuracy: 0.3588 - val_loss: 1.7378 - val_accuracy: 0.3153\n",
      "Epoch 135/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7176 - accuracy: 0.3531 - val_loss: 1.6901 - val_accuracy: 0.3834\n",
      "Epoch 136/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.7163 - accuracy: 0.3502 - val_loss: 1.7355 - val_accuracy: 0.3581\n",
      "Epoch 137/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7122 - accuracy: 0.3550 - val_loss: 1.6989 - val_accuracy: 0.3644\n",
      "Epoch 138/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7130 - accuracy: 0.3547 - val_loss: 1.6747 - val_accuracy: 0.3682\n",
      "Epoch 139/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7123 - accuracy: 0.3553 - val_loss: 1.6913 - val_accuracy: 0.3644\n",
      "Epoch 140/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7110 - accuracy: 0.3585 - val_loss: 1.7253 - val_accuracy: 0.3518\n",
      "Epoch 141/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.7085 - accuracy: 0.3552 - val_loss: 1.6773 - val_accuracy: 0.3783\n",
      "Epoch 142/500\n",
      "395/395 [==============================] - 47s 118ms/step - loss: 1.7017 - accuracy: 0.3596 - val_loss: 1.6829 - val_accuracy: 0.3821\n",
      "Epoch 143/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.7029 - accuracy: 0.3583 - val_loss: 1.6511 - val_accuracy: 0.4010\n",
      "Epoch 144/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.7044 - accuracy: 0.3571 - val_loss: 1.6532 - val_accuracy: 0.3909\n",
      "Epoch 145/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.6973 - accuracy: 0.3623 - val_loss: 1.6727 - val_accuracy: 0.3897\n",
      "Epoch 146/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.6980 - accuracy: 0.3616 - val_loss: 1.6487 - val_accuracy: 0.4073\n",
      "Epoch 147/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.7005 - accuracy: 0.3700 - val_loss: 1.6753 - val_accuracy: 0.3834\n",
      "Epoch 148/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.7002 - accuracy: 0.3631 - val_loss: 1.7815 - val_accuracy: 0.3329\n",
      "Epoch 149/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6979 - accuracy: 0.3609 - val_loss: 1.7187 - val_accuracy: 0.3544\n",
      "Epoch 150/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6968 - accuracy: 0.3708 - val_loss: 1.6559 - val_accuracy: 0.3884\n",
      "Epoch 151/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6917 - accuracy: 0.3659 - val_loss: 1.6245 - val_accuracy: 0.4098\n",
      "Epoch 152/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6880 - accuracy: 0.3746 - val_loss: 1.6462 - val_accuracy: 0.3897\n",
      "Epoch 153/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6927 - accuracy: 0.3599 - val_loss: 1.6503 - val_accuracy: 0.3846\n",
      "Epoch 154/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6922 - accuracy: 0.3582 - val_loss: 1.7536 - val_accuracy: 0.3342\n",
      "Epoch 155/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6907 - accuracy: 0.3631 - val_loss: 1.6469 - val_accuracy: 0.3707\n",
      "Epoch 156/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.6882 - accuracy: 0.3655 - val_loss: 1.6528 - val_accuracy: 0.4048\n",
      "Epoch 157/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6855 - accuracy: 0.3678 - val_loss: 1.6440 - val_accuracy: 0.3909\n",
      "Epoch 158/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.6812 - accuracy: 0.3704 - val_loss: 1.6350 - val_accuracy: 0.3985\n",
      "Epoch 159/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6827 - accuracy: 0.3745 - val_loss: 1.6557 - val_accuracy: 0.3821\n",
      "Epoch 160/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6742 - accuracy: 0.3704 - val_loss: 1.6290 - val_accuracy: 0.4174\n",
      "Epoch 161/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6803 - accuracy: 0.3658 - val_loss: 1.6318 - val_accuracy: 0.4023\n",
      "Epoch 162/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.6782 - accuracy: 0.3716 - val_loss: 1.6231 - val_accuracy: 0.4035\n",
      "Epoch 163/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6744 - accuracy: 0.3748 - val_loss: 1.7967 - val_accuracy: 0.3216\n",
      "Epoch 164/500\n",
      "395/395 [==============================] - 48s 123ms/step - loss: 1.6771 - accuracy: 0.3708 - val_loss: 1.6708 - val_accuracy: 0.3972\n",
      "Epoch 165/500\n",
      "395/395 [==============================] - 49s 125ms/step - loss: 1.6775 - accuracy: 0.3751 - val_loss: 1.6586 - val_accuracy: 0.3909\n",
      "Epoch 166/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.6732 - accuracy: 0.3740 - val_loss: 1.6384 - val_accuracy: 0.3985\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 48s 121ms/step - loss: 1.6744 - accuracy: 0.3712 - val_loss: 1.6916 - val_accuracy: 0.3909\n",
      "Epoch 168/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.6718 - accuracy: 0.3780 - val_loss: 1.6427 - val_accuracy: 0.4111\n",
      "Epoch 169/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.6756 - accuracy: 0.3721 - val_loss: 1.6849 - val_accuracy: 0.3758\n",
      "Epoch 170/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.6730 - accuracy: 0.3746 - val_loss: 1.6388 - val_accuracy: 0.4073\n",
      "Epoch 171/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.6634 - accuracy: 0.3764 - val_loss: 1.6658 - val_accuracy: 0.3922\n",
      "Epoch 172/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.6657 - accuracy: 0.3784 - val_loss: 1.6459 - val_accuracy: 0.3972\n",
      "Epoch 173/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.6629 - accuracy: 0.3767 - val_loss: 1.6903 - val_accuracy: 0.3909\n",
      "Epoch 174/500\n",
      "395/395 [==============================] - 48s 123ms/step - loss: 1.6673 - accuracy: 0.3827 - val_loss: 1.6453 - val_accuracy: 0.3897\n",
      "Epoch 175/500\n",
      "395/395 [==============================] - 49s 123ms/step - loss: 1.6620 - accuracy: 0.3740 - val_loss: 1.6296 - val_accuracy: 0.4136\n",
      "Epoch 176/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.6569 - accuracy: 0.3781 - val_loss: 1.7078 - val_accuracy: 0.3531\n",
      "Epoch 177/500\n",
      "395/395 [==============================] - 48s 121ms/step - loss: 1.6619 - accuracy: 0.3781 - val_loss: 1.6026 - val_accuracy: 0.4061\n",
      "Epoch 178/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.6600 - accuracy: 0.3784 - val_loss: 1.6331 - val_accuracy: 0.4136\n",
      "Epoch 179/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6604 - accuracy: 0.3875 - val_loss: 1.6218 - val_accuracy: 0.4048\n",
      "Epoch 180/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6573 - accuracy: 0.3861 - val_loss: 1.6016 - val_accuracy: 0.4023\n",
      "Epoch 181/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6550 - accuracy: 0.3797 - val_loss: 1.6708 - val_accuracy: 0.4023\n",
      "Epoch 182/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.6555 - accuracy: 0.3811 - val_loss: 1.6137 - val_accuracy: 0.4288\n",
      "Epoch 183/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6545 - accuracy: 0.3878 - val_loss: 1.6525 - val_accuracy: 0.4262\n",
      "Epoch 184/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6555 - accuracy: 0.3849 - val_loss: 1.7839 - val_accuracy: 0.3304\n",
      "Epoch 185/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6660 - accuracy: 0.3854 - val_loss: 1.6669 - val_accuracy: 0.3997\n",
      "Epoch 186/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6526 - accuracy: 0.3811 - val_loss: 1.6624 - val_accuracy: 0.3834\n",
      "Epoch 187/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6508 - accuracy: 0.3832 - val_loss: 1.6253 - val_accuracy: 0.4048\n",
      "Epoch 188/500\n",
      "395/395 [==============================] - 48s 120ms/step - loss: 1.6518 - accuracy: 0.3878 - val_loss: 1.6089 - val_accuracy: 0.4250\n",
      "Epoch 189/500\n",
      "395/395 [==============================] - 47s 119ms/step - loss: 1.6440 - accuracy: 0.3910 - val_loss: 1.6218 - val_accuracy: 0.4174\n",
      "Epoch 190/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6469 - accuracy: 0.3870 - val_loss: 1.6420 - val_accuracy: 0.4061\n",
      "Epoch 191/500\n",
      "395/395 [==============================] - 47s 119ms/step - loss: 1.6420 - accuracy: 0.3884 - val_loss: 1.6130 - val_accuracy: 0.4111\n",
      "Epoch 192/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6378 - accuracy: 0.3867 - val_loss: 1.6345 - val_accuracy: 0.4149\n",
      "Epoch 193/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6384 - accuracy: 0.3918 - val_loss: 1.5773 - val_accuracy: 0.4250\n",
      "Epoch 194/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6338 - accuracy: 0.3952 - val_loss: 1.7173 - val_accuracy: 0.3745\n",
      "Epoch 195/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6368 - accuracy: 0.3926 - val_loss: 1.6389 - val_accuracy: 0.4224\n",
      "Epoch 196/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6380 - accuracy: 0.3965 - val_loss: 1.5945 - val_accuracy: 0.4288\n",
      "Epoch 197/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.6352 - accuracy: 0.3940 - val_loss: 1.6019 - val_accuracy: 0.4426\n",
      "Epoch 198/500\n",
      "395/395 [==============================] - 42s 107ms/step - loss: 1.6297 - accuracy: 0.3911 - val_loss: 1.5581 - val_accuracy: 0.4376\n",
      "Epoch 199/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6297 - accuracy: 0.3956 - val_loss: 1.6703 - val_accuracy: 0.3670\n",
      "Epoch 200/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6349 - accuracy: 0.3995 - val_loss: 1.5884 - val_accuracy: 0.4325\n",
      "Epoch 201/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6394 - accuracy: 0.3935 - val_loss: 1.5863 - val_accuracy: 0.4136\n",
      "Epoch 202/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6290 - accuracy: 0.3967 - val_loss: 1.5654 - val_accuracy: 0.4363\n",
      "Epoch 203/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6283 - accuracy: 0.3911 - val_loss: 1.5752 - val_accuracy: 0.4515\n",
      "Epoch 204/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6238 - accuracy: 0.3960 - val_loss: 1.5639 - val_accuracy: 0.4275\n",
      "Epoch 205/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6223 - accuracy: 0.3962 - val_loss: 1.6458 - val_accuracy: 0.4035\n",
      "Epoch 206/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6183 - accuracy: 0.3983 - val_loss: 1.5771 - val_accuracy: 0.4351\n",
      "Epoch 207/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6230 - accuracy: 0.3989 - val_loss: 1.6255 - val_accuracy: 0.4174\n",
      "Epoch 208/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6186 - accuracy: 0.4000 - val_loss: 1.6047 - val_accuracy: 0.4111\n",
      "Epoch 209/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6182 - accuracy: 0.4005 - val_loss: 1.5866 - val_accuracy: 0.4338\n",
      "Epoch 210/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6136 - accuracy: 0.3990 - val_loss: 1.5982 - val_accuracy: 0.4250\n",
      "Epoch 211/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6110 - accuracy: 0.4074 - val_loss: 1.5568 - val_accuracy: 0.4338\n",
      "Epoch 212/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.6122 - accuracy: 0.4073 - val_loss: 1.5709 - val_accuracy: 0.4477\n",
      "Epoch 213/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6131 - accuracy: 0.4055 - val_loss: 1.5377 - val_accuracy: 0.4515\n",
      "Epoch 214/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6058 - accuracy: 0.4036 - val_loss: 1.5394 - val_accuracy: 0.4515\n",
      "Epoch 215/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6076 - accuracy: 0.4019 - val_loss: 1.5847 - val_accuracy: 0.4451\n",
      "Epoch 216/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6111 - accuracy: 0.4021 - val_loss: 1.6199 - val_accuracy: 0.4174\n",
      "Epoch 217/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6071 - accuracy: 0.4030 - val_loss: 1.5740 - val_accuracy: 0.4325\n",
      "Epoch 218/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6027 - accuracy: 0.4100 - val_loss: 1.7581 - val_accuracy: 0.3506\n",
      "Epoch 219/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6049 - accuracy: 0.4168 - val_loss: 1.5467 - val_accuracy: 0.4489\n",
      "Epoch 220/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6017 - accuracy: 0.4138 - val_loss: 1.6297 - val_accuracy: 0.4111\n",
      "Epoch 221/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6041 - accuracy: 0.4087 - val_loss: 1.5886 - val_accuracy: 0.4224\n",
      "Epoch 222/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.6035 - accuracy: 0.4087 - val_loss: 1.5558 - val_accuracy: 0.4401\n",
      "Epoch 223/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6034 - accuracy: 0.4100 - val_loss: 1.5889 - val_accuracy: 0.4250\n",
      "Epoch 224/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5950 - accuracy: 0.4116 - val_loss: 1.5858 - val_accuracy: 0.4414\n",
      "Epoch 225/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5952 - accuracy: 0.4143 - val_loss: 1.5587 - val_accuracy: 0.4426\n",
      "Epoch 226/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5953 - accuracy: 0.4097 - val_loss: 1.5984 - val_accuracy: 0.4174\n",
      "Epoch 227/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.6002 - accuracy: 0.4122 - val_loss: 1.5303 - val_accuracy: 0.4603\n",
      "Epoch 228/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5963 - accuracy: 0.4105 - val_loss: 1.5783 - val_accuracy: 0.4124\n",
      "Epoch 229/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5901 - accuracy: 0.4173 - val_loss: 1.5848 - val_accuracy: 0.4388\n",
      "Epoch 230/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5865 - accuracy: 0.4151 - val_loss: 1.5374 - val_accuracy: 0.4540\n",
      "Epoch 231/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5832 - accuracy: 0.4144 - val_loss: 1.5690 - val_accuracy: 0.4250\n",
      "Epoch 232/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5898 - accuracy: 0.4114 - val_loss: 1.5509 - val_accuracy: 0.4477\n",
      "Epoch 233/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5816 - accuracy: 0.4122 - val_loss: 1.5184 - val_accuracy: 0.4615\n",
      "Epoch 234/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5815 - accuracy: 0.4211 - val_loss: 1.5580 - val_accuracy: 0.4426\n",
      "Epoch 235/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5815 - accuracy: 0.4144 - val_loss: 1.5086 - val_accuracy: 0.4666\n",
      "Epoch 236/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5772 - accuracy: 0.4136 - val_loss: 1.5187 - val_accuracy: 0.4578\n",
      "Epoch 237/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5789 - accuracy: 0.4200 - val_loss: 1.5077 - val_accuracy: 0.4527\n",
      "Epoch 238/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5732 - accuracy: 0.4260 - val_loss: 1.5161 - val_accuracy: 0.4716\n",
      "Epoch 239/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5710 - accuracy: 0.4238 - val_loss: 1.5713 - val_accuracy: 0.4224\n",
      "Epoch 240/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5777 - accuracy: 0.4154 - val_loss: 1.5257 - val_accuracy: 0.4590\n",
      "Epoch 241/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5680 - accuracy: 0.4274 - val_loss: 1.6386 - val_accuracy: 0.3972\n",
      "Epoch 242/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5657 - accuracy: 0.4249 - val_loss: 1.6200 - val_accuracy: 0.4073\n",
      "Epoch 243/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5658 - accuracy: 0.4255 - val_loss: 1.5401 - val_accuracy: 0.4439\n",
      "Epoch 244/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5674 - accuracy: 0.4238 - val_loss: 1.5171 - val_accuracy: 0.4628\n",
      "Epoch 245/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5655 - accuracy: 0.4260 - val_loss: 1.5123 - val_accuracy: 0.4578\n",
      "Epoch 246/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5554 - accuracy: 0.4319 - val_loss: 1.5041 - val_accuracy: 0.4678\n",
      "Epoch 247/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5564 - accuracy: 0.4263 - val_loss: 1.5982 - val_accuracy: 0.4325\n",
      "Epoch 248/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5539 - accuracy: 0.4353 - val_loss: 1.4898 - val_accuracy: 0.4792\n",
      "Epoch 249/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5543 - accuracy: 0.4333 - val_loss: 1.5011 - val_accuracy: 0.4590\n",
      "Epoch 250/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5588 - accuracy: 0.4252 - val_loss: 1.5909 - val_accuracy: 0.4124\n",
      "Epoch 251/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5544 - accuracy: 0.4303 - val_loss: 1.5637 - val_accuracy: 0.4451\n",
      "Epoch 252/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5492 - accuracy: 0.4304 - val_loss: 1.5718 - val_accuracy: 0.4351\n",
      "Epoch 253/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5547 - accuracy: 0.4309 - val_loss: 1.5519 - val_accuracy: 0.4376\n",
      "Epoch 254/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5491 - accuracy: 0.4331 - val_loss: 1.5101 - val_accuracy: 0.4741\n",
      "Epoch 255/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5495 - accuracy: 0.4273 - val_loss: 1.5483 - val_accuracy: 0.4489\n",
      "Epoch 256/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5427 - accuracy: 0.4352 - val_loss: 1.5229 - val_accuracy: 0.4578\n",
      "Epoch 257/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5478 - accuracy: 0.4317 - val_loss: 1.4807 - val_accuracy: 0.4704\n",
      "Epoch 258/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5386 - accuracy: 0.4380 - val_loss: 1.4960 - val_accuracy: 0.4641\n",
      "Epoch 259/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5388 - accuracy: 0.4314 - val_loss: 1.4773 - val_accuracy: 0.4880\n",
      "Epoch 260/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.5399 - accuracy: 0.4357 - val_loss: 1.5319 - val_accuracy: 0.4502\n",
      "Epoch 261/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5449 - accuracy: 0.4366 - val_loss: 1.5429 - val_accuracy: 0.4338\n",
      "Epoch 262/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5368 - accuracy: 0.4345 - val_loss: 1.5602 - val_accuracy: 0.4439\n",
      "Epoch 263/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5318 - accuracy: 0.4384 - val_loss: 1.4924 - val_accuracy: 0.4842\n",
      "Epoch 264/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5332 - accuracy: 0.4380 - val_loss: 1.4873 - val_accuracy: 0.4741\n",
      "Epoch 265/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5244 - accuracy: 0.4409 - val_loss: 1.4860 - val_accuracy: 0.4842\n",
      "Epoch 266/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5285 - accuracy: 0.4312 - val_loss: 1.4785 - val_accuracy: 0.4817\n",
      "Epoch 267/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5281 - accuracy: 0.4463 - val_loss: 1.5432 - val_accuracy: 0.4451\n",
      "Epoch 268/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5252 - accuracy: 0.4436 - val_loss: 1.4661 - val_accuracy: 0.4880\n",
      "Epoch 269/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5225 - accuracy: 0.4384 - val_loss: 1.4877 - val_accuracy: 0.4716\n",
      "Epoch 270/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5240 - accuracy: 0.4464 - val_loss: 1.5214 - val_accuracy: 0.4515\n",
      "Epoch 271/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5179 - accuracy: 0.4436 - val_loss: 1.5251 - val_accuracy: 0.4502\n",
      "Epoch 272/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.5179 - accuracy: 0.4388 - val_loss: 1.5190 - val_accuracy: 0.4590\n",
      "Epoch 273/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5222 - accuracy: 0.4450 - val_loss: 1.4866 - val_accuracy: 0.4792\n",
      "Epoch 274/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5153 - accuracy: 0.4409 - val_loss: 1.4821 - val_accuracy: 0.4779\n",
      "Epoch 275/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5117 - accuracy: 0.4433 - val_loss: 1.5002 - val_accuracy: 0.4704\n",
      "Epoch 276/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5169 - accuracy: 0.4431 - val_loss: 1.5599 - val_accuracy: 0.4300\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5128 - accuracy: 0.4448 - val_loss: 1.4715 - val_accuracy: 0.4830\n",
      "Epoch 278/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5073 - accuracy: 0.4460 - val_loss: 1.5068 - val_accuracy: 0.4628\n",
      "Epoch 279/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5078 - accuracy: 0.4460 - val_loss: 1.4808 - val_accuracy: 0.4716\n",
      "Epoch 280/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5127 - accuracy: 0.4439 - val_loss: 1.5822 - val_accuracy: 0.4098\n",
      "Epoch 281/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5070 - accuracy: 0.4487 - val_loss: 1.5600 - val_accuracy: 0.4439\n",
      "Epoch 282/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5013 - accuracy: 0.4556 - val_loss: 1.6760 - val_accuracy: 0.3531\n",
      "Epoch 283/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5049 - accuracy: 0.4585 - val_loss: 1.5042 - val_accuracy: 0.4628\n",
      "Epoch 284/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5001 - accuracy: 0.4510 - val_loss: 1.4939 - val_accuracy: 0.4678\n",
      "Epoch 285/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5053 - accuracy: 0.4512 - val_loss: 1.5287 - val_accuracy: 0.4540\n",
      "Epoch 286/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5041 - accuracy: 0.4479 - val_loss: 1.5872 - val_accuracy: 0.4111\n",
      "Epoch 287/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.5014 - accuracy: 0.4502 - val_loss: 1.4776 - val_accuracy: 0.4918\n",
      "Epoch 288/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4952 - accuracy: 0.4561 - val_loss: 1.4980 - val_accuracy: 0.4515\n",
      "Epoch 289/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4983 - accuracy: 0.4561 - val_loss: 1.5856 - val_accuracy: 0.4300\n",
      "Epoch 290/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4937 - accuracy: 0.4537 - val_loss: 1.4878 - val_accuracy: 0.4741\n",
      "Epoch 291/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4943 - accuracy: 0.4532 - val_loss: 1.5464 - val_accuracy: 0.4464\n",
      "Epoch 292/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4995 - accuracy: 0.4552 - val_loss: 1.5774 - val_accuracy: 0.4388\n",
      "Epoch 293/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4913 - accuracy: 0.4604 - val_loss: 1.5151 - val_accuracy: 0.4641\n",
      "Epoch 294/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4919 - accuracy: 0.4612 - val_loss: 1.4756 - val_accuracy: 0.4729\n",
      "Epoch 295/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4888 - accuracy: 0.4550 - val_loss: 1.5156 - val_accuracy: 0.4641\n",
      "Epoch 296/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4845 - accuracy: 0.4588 - val_loss: 1.5034 - val_accuracy: 0.4590\n",
      "Epoch 297/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4861 - accuracy: 0.4567 - val_loss: 1.4805 - val_accuracy: 0.4691\n",
      "Epoch 298/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4809 - accuracy: 0.4615 - val_loss: 1.4837 - val_accuracy: 0.4754\n",
      "Epoch 299/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4822 - accuracy: 0.4569 - val_loss: 1.4703 - val_accuracy: 0.4817\n",
      "Epoch 300/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4793 - accuracy: 0.4658 - val_loss: 1.4849 - val_accuracy: 0.4779\n",
      "Epoch 301/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4774 - accuracy: 0.4618 - val_loss: 1.4926 - val_accuracy: 0.4603\n",
      "Epoch 302/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4740 - accuracy: 0.4609 - val_loss: 1.5781 - val_accuracy: 0.4313\n",
      "Epoch 303/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4716 - accuracy: 0.4578 - val_loss: 1.5397 - val_accuracy: 0.4552\n",
      "Epoch 304/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.4718 - accuracy: 0.4632 - val_loss: 1.4915 - val_accuracy: 0.4565\n",
      "Epoch 305/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4744 - accuracy: 0.4647 - val_loss: 1.5061 - val_accuracy: 0.4628\n",
      "Epoch 306/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4721 - accuracy: 0.4697 - val_loss: 1.5265 - val_accuracy: 0.4502\n",
      "Epoch 307/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4619 - accuracy: 0.4686 - val_loss: 1.5013 - val_accuracy: 0.4628\n",
      "Epoch 308/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4674 - accuracy: 0.4667 - val_loss: 1.4964 - val_accuracy: 0.4817\n",
      "Epoch 309/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4676 - accuracy: 0.4705 - val_loss: 1.4828 - val_accuracy: 0.4704\n",
      "Epoch 310/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.4633 - accuracy: 0.4731 - val_loss: 1.5668 - val_accuracy: 0.4464\n",
      "Epoch 311/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4565 - accuracy: 0.4715 - val_loss: 1.4688 - val_accuracy: 0.4868\n",
      "Epoch 312/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4608 - accuracy: 0.4704 - val_loss: 1.5328 - val_accuracy: 0.4603\n",
      "Epoch 313/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4607 - accuracy: 0.4707 - val_loss: 1.5252 - val_accuracy: 0.4388\n",
      "Epoch 314/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4497 - accuracy: 0.4726 - val_loss: 1.4940 - val_accuracy: 0.4729\n",
      "Epoch 315/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4520 - accuracy: 0.4751 - val_loss: 1.6717 - val_accuracy: 0.4010\n",
      "Epoch 316/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4549 - accuracy: 0.4688 - val_loss: 1.4951 - val_accuracy: 0.4653\n",
      "Epoch 317/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4488 - accuracy: 0.4791 - val_loss: 1.5466 - val_accuracy: 0.4515\n",
      "Epoch 318/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4521 - accuracy: 0.4759 - val_loss: 1.4491 - val_accuracy: 0.4842\n",
      "Epoch 319/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4455 - accuracy: 0.4791 - val_loss: 1.6584 - val_accuracy: 0.3972\n",
      "Epoch 320/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4403 - accuracy: 0.4837 - val_loss: 1.4914 - val_accuracy: 0.4767\n",
      "Epoch 321/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4473 - accuracy: 0.4751 - val_loss: 1.4518 - val_accuracy: 0.4994\n",
      "Epoch 322/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4418 - accuracy: 0.4777 - val_loss: 1.4812 - val_accuracy: 0.4767\n",
      "Epoch 323/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4428 - accuracy: 0.4762 - val_loss: 1.5084 - val_accuracy: 0.4628\n",
      "Epoch 324/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4332 - accuracy: 0.4837 - val_loss: 1.4861 - val_accuracy: 0.4477\n",
      "Epoch 325/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4370 - accuracy: 0.4830 - val_loss: 1.4547 - val_accuracy: 0.4893\n",
      "Epoch 326/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4316 - accuracy: 0.4861 - val_loss: 1.6041 - val_accuracy: 0.4275\n",
      "Epoch 327/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.4351 - accuracy: 0.4805 - val_loss: 1.4822 - val_accuracy: 0.4653\n",
      "Epoch 328/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4350 - accuracy: 0.4807 - val_loss: 1.5580 - val_accuracy: 0.4439\n",
      "Epoch 329/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4297 - accuracy: 0.4811 - val_loss: 1.5399 - val_accuracy: 0.4477\n",
      "Epoch 330/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4365 - accuracy: 0.4835 - val_loss: 1.5121 - val_accuracy: 0.4653\n",
      "Epoch 331/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4235 - accuracy: 0.4851 - val_loss: 1.5288 - val_accuracy: 0.4754\n",
      "Epoch 332/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4239 - accuracy: 0.4894 - val_loss: 1.4924 - val_accuracy: 0.4817\n",
      "Epoch 333/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4225 - accuracy: 0.4816 - val_loss: 1.5111 - val_accuracy: 0.4691\n",
      "Epoch 334/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4221 - accuracy: 0.4886 - val_loss: 1.4605 - val_accuracy: 0.4729\n",
      "Epoch 335/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4140 - accuracy: 0.4948 - val_loss: 1.6266 - val_accuracy: 0.4149\n",
      "Epoch 336/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4172 - accuracy: 0.4876 - val_loss: 1.5023 - val_accuracy: 0.4779\n",
      "Epoch 337/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4205 - accuracy: 0.4957 - val_loss: 1.5117 - val_accuracy: 0.4729\n",
      "Epoch 338/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4151 - accuracy: 0.4911 - val_loss: 1.4406 - val_accuracy: 0.4792\n",
      "Epoch 339/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4152 - accuracy: 0.4997 - val_loss: 1.4475 - val_accuracy: 0.4830\n",
      "Epoch 340/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4110 - accuracy: 0.4965 - val_loss: 1.4552 - val_accuracy: 0.4842\n",
      "Epoch 341/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4182 - accuracy: 0.4861 - val_loss: 1.4906 - val_accuracy: 0.4931\n",
      "Epoch 342/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.4124 - accuracy: 0.4887 - val_loss: 1.5314 - val_accuracy: 0.4515\n",
      "Epoch 343/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4118 - accuracy: 0.4941 - val_loss: 1.4792 - val_accuracy: 0.4956\n",
      "Epoch 344/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.4151 - accuracy: 0.4897 - val_loss: 1.4839 - val_accuracy: 0.4691\n",
      "Epoch 345/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4079 - accuracy: 0.4995 - val_loss: 1.4802 - val_accuracy: 0.4792\n",
      "Epoch 346/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4049 - accuracy: 0.4892 - val_loss: 1.4447 - val_accuracy: 0.4893\n",
      "Epoch 347/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.4095 - accuracy: 0.4945 - val_loss: 1.4286 - val_accuracy: 0.5032\n",
      "Epoch 348/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3971 - accuracy: 0.4979 - val_loss: 1.4831 - val_accuracy: 0.4880\n",
      "Epoch 349/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.3976 - accuracy: 0.4965 - val_loss: 1.4742 - val_accuracy: 0.4893\n",
      "Epoch 350/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3976 - accuracy: 0.5024 - val_loss: 1.4602 - val_accuracy: 0.4905\n",
      "Epoch 351/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3923 - accuracy: 0.4981 - val_loss: 1.4886 - val_accuracy: 0.4931\n",
      "Epoch 352/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3949 - accuracy: 0.5011 - val_loss: 1.4345 - val_accuracy: 0.4842\n",
      "Epoch 353/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3883 - accuracy: 0.5010 - val_loss: 1.4497 - val_accuracy: 0.5019\n",
      "Epoch 354/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3879 - accuracy: 0.5002 - val_loss: 1.4559 - val_accuracy: 0.4918\n",
      "Epoch 355/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.3966 - accuracy: 0.4978 - val_loss: 1.4447 - val_accuracy: 0.4918\n",
      "Epoch 356/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3893 - accuracy: 0.5113 - val_loss: 1.4343 - val_accuracy: 0.4994\n",
      "Epoch 357/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3910 - accuracy: 0.5008 - val_loss: 1.4738 - val_accuracy: 0.4729\n",
      "Epoch 358/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3901 - accuracy: 0.4990 - val_loss: 1.4309 - val_accuracy: 0.4779\n",
      "Epoch 359/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3834 - accuracy: 0.5049 - val_loss: 1.4626 - val_accuracy: 0.4893\n",
      "Epoch 360/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3796 - accuracy: 0.5035 - val_loss: 1.4500 - val_accuracy: 0.4830\n",
      "Epoch 361/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.3781 - accuracy: 0.5059 - val_loss: 1.5057 - val_accuracy: 0.4716\n",
      "Epoch 362/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3763 - accuracy: 0.5049 - val_loss: 1.4841 - val_accuracy: 0.4716\n",
      "Epoch 363/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3809 - accuracy: 0.5105 - val_loss: 1.5034 - val_accuracy: 0.4716\n",
      "Epoch 364/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.3792 - accuracy: 0.5055 - val_loss: 1.4637 - val_accuracy: 0.4880\n",
      "Epoch 365/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3774 - accuracy: 0.5095 - val_loss: 1.4097 - val_accuracy: 0.5145\n",
      "Epoch 366/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3784 - accuracy: 0.5082 - val_loss: 1.4585 - val_accuracy: 0.4880\n",
      "Epoch 367/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.3735 - accuracy: 0.5068 - val_loss: 1.5278 - val_accuracy: 0.4515\n",
      "Epoch 368/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3735 - accuracy: 0.5065 - val_loss: 1.4518 - val_accuracy: 0.5057\n",
      "Epoch 369/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3690 - accuracy: 0.5084 - val_loss: 1.5935 - val_accuracy: 0.4376\n",
      "Epoch 370/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3727 - accuracy: 0.5133 - val_loss: 1.4777 - val_accuracy: 0.4830\n",
      "Epoch 371/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3675 - accuracy: 0.5087 - val_loss: 1.4460 - val_accuracy: 0.4792\n",
      "Epoch 372/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3699 - accuracy: 0.5130 - val_loss: 1.5385 - val_accuracy: 0.4489\n",
      "Epoch 373/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3701 - accuracy: 0.5109 - val_loss: 1.4521 - val_accuracy: 0.4893\n",
      "Epoch 374/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3649 - accuracy: 0.5151 - val_loss: 1.5292 - val_accuracy: 0.4590\n",
      "Epoch 375/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3545 - accuracy: 0.5151 - val_loss: 1.4569 - val_accuracy: 0.4880\n",
      "Epoch 376/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3685 - accuracy: 0.5113 - val_loss: 1.4301 - val_accuracy: 0.4905\n",
      "Epoch 377/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3623 - accuracy: 0.5135 - val_loss: 1.5132 - val_accuracy: 0.4754\n",
      "Epoch 378/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3623 - accuracy: 0.5203 - val_loss: 1.4678 - val_accuracy: 0.4905\n",
      "Epoch 379/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3575 - accuracy: 0.5144 - val_loss: 1.4097 - val_accuracy: 0.5032\n",
      "Epoch 380/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3599 - accuracy: 0.5181 - val_loss: 1.4862 - val_accuracy: 0.4805\n",
      "Epoch 381/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.3604 - accuracy: 0.5130 - val_loss: 1.4416 - val_accuracy: 0.4931\n",
      "Epoch 382/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3579 - accuracy: 0.5109 - val_loss: 1.5295 - val_accuracy: 0.4729\n",
      "Epoch 383/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3546 - accuracy: 0.5209 - val_loss: 1.4987 - val_accuracy: 0.4905\n",
      "Epoch 384/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3502 - accuracy: 0.5165 - val_loss: 1.4478 - val_accuracy: 0.4918\n",
      "Epoch 385/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3522 - accuracy: 0.5151 - val_loss: 1.4273 - val_accuracy: 0.4918\n",
      "Epoch 386/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3465 - accuracy: 0.5231 - val_loss: 1.4228 - val_accuracy: 0.5019\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3478 - accuracy: 0.5214 - val_loss: 1.5408 - val_accuracy: 0.4716\n",
      "Epoch 388/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3435 - accuracy: 0.5216 - val_loss: 1.4246 - val_accuracy: 0.4994\n",
      "Epoch 389/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3413 - accuracy: 0.5182 - val_loss: 1.5141 - val_accuracy: 0.4729\n",
      "Epoch 390/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.3439 - accuracy: 0.5173 - val_loss: 1.4968 - val_accuracy: 0.4540\n",
      "Epoch 391/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3421 - accuracy: 0.5211 - val_loss: 1.4390 - val_accuracy: 0.4994\n",
      "Epoch 392/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3381 - accuracy: 0.5238 - val_loss: 1.5111 - val_accuracy: 0.4641\n",
      "Epoch 393/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.3422 - accuracy: 0.5203 - val_loss: 1.4844 - val_accuracy: 0.4817\n",
      "Epoch 394/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3395 - accuracy: 0.5293 - val_loss: 1.4558 - val_accuracy: 0.4931\n",
      "Epoch 395/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.3379 - accuracy: 0.5242 - val_loss: 1.4404 - val_accuracy: 0.4868\n",
      "Epoch 396/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3375 - accuracy: 0.5260 - val_loss: 1.4897 - val_accuracy: 0.4893\n",
      "Epoch 397/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3341 - accuracy: 0.5189 - val_loss: 1.4912 - val_accuracy: 0.4817\n",
      "Epoch 398/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3326 - accuracy: 0.5271 - val_loss: 1.4214 - val_accuracy: 0.5019\n",
      "Epoch 399/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3332 - accuracy: 0.5198 - val_loss: 1.4206 - val_accuracy: 0.5044\n",
      "Epoch 400/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3280 - accuracy: 0.5238 - val_loss: 1.4697 - val_accuracy: 0.4880\n",
      "Epoch 401/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3301 - accuracy: 0.5282 - val_loss: 1.4237 - val_accuracy: 0.5019\n",
      "Epoch 402/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3316 - accuracy: 0.5246 - val_loss: 1.4193 - val_accuracy: 0.5032\n",
      "Epoch 403/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3264 - accuracy: 0.5298 - val_loss: 1.4309 - val_accuracy: 0.4981\n",
      "Epoch 404/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3290 - accuracy: 0.5269 - val_loss: 1.5024 - val_accuracy: 0.4767\n",
      "Epoch 405/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3168 - accuracy: 0.5325 - val_loss: 1.5311 - val_accuracy: 0.4767\n",
      "Epoch 406/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3203 - accuracy: 0.5295 - val_loss: 1.4713 - val_accuracy: 0.4842\n",
      "Epoch 407/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3122 - accuracy: 0.5365 - val_loss: 1.4246 - val_accuracy: 0.4842\n",
      "Epoch 408/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3210 - accuracy: 0.5268 - val_loss: 1.4010 - val_accuracy: 0.5208\n",
      "Epoch 409/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3218 - accuracy: 0.5265 - val_loss: 1.5304 - val_accuracy: 0.4502\n",
      "Epoch 410/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3215 - accuracy: 0.5325 - val_loss: 1.4293 - val_accuracy: 0.5107\n",
      "Epoch 411/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3159 - accuracy: 0.5295 - val_loss: 1.5538 - val_accuracy: 0.4414\n",
      "Epoch 412/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3145 - accuracy: 0.5279 - val_loss: 1.4234 - val_accuracy: 0.4931\n",
      "Epoch 413/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.3100 - accuracy: 0.5306 - val_loss: 1.4554 - val_accuracy: 0.4931\n",
      "Epoch 414/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3104 - accuracy: 0.5355 - val_loss: 1.4485 - val_accuracy: 0.4880\n",
      "Epoch 415/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2996 - accuracy: 0.5391 - val_loss: 1.4773 - val_accuracy: 0.4893\n",
      "Epoch 416/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3075 - accuracy: 0.5292 - val_loss: 1.4288 - val_accuracy: 0.5158\n",
      "Epoch 417/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3076 - accuracy: 0.5344 - val_loss: 1.4294 - val_accuracy: 0.4855\n",
      "Epoch 418/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3078 - accuracy: 0.5328 - val_loss: 1.4540 - val_accuracy: 0.4893\n",
      "Epoch 419/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.3050 - accuracy: 0.5365 - val_loss: 1.4604 - val_accuracy: 0.5019\n",
      "Epoch 420/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3069 - accuracy: 0.5357 - val_loss: 1.4820 - val_accuracy: 0.4792\n",
      "Epoch 421/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.2987 - accuracy: 0.5349 - val_loss: 1.4483 - val_accuracy: 0.4880\n",
      "Epoch 422/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3023 - accuracy: 0.5361 - val_loss: 1.4082 - val_accuracy: 0.5170\n",
      "Epoch 423/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2957 - accuracy: 0.5371 - val_loss: 1.4488 - val_accuracy: 0.4918\n",
      "Epoch 424/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2930 - accuracy: 0.5338 - val_loss: 1.4381 - val_accuracy: 0.4918\n",
      "Epoch 425/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2947 - accuracy: 0.5418 - val_loss: 1.4174 - val_accuracy: 0.5082\n",
      "Epoch 426/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2934 - accuracy: 0.5374 - val_loss: 1.4515 - val_accuracy: 0.4830\n",
      "Epoch 427/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2982 - accuracy: 0.5365 - val_loss: 1.4346 - val_accuracy: 0.4817\n",
      "Epoch 428/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2891 - accuracy: 0.5406 - val_loss: 1.4130 - val_accuracy: 0.5032\n",
      "Epoch 429/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2953 - accuracy: 0.5418 - val_loss: 1.5789 - val_accuracy: 0.4527\n",
      "Epoch 430/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2895 - accuracy: 0.5399 - val_loss: 1.4461 - val_accuracy: 0.4830\n",
      "Epoch 431/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2897 - accuracy: 0.5412 - val_loss: 1.4090 - val_accuracy: 0.5006\n",
      "Epoch 432/500\n",
      "395/395 [==============================] - 45s 114ms/step - loss: 1.2825 - accuracy: 0.5423 - val_loss: 1.4208 - val_accuracy: 0.4868\n",
      "Epoch 433/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2821 - accuracy: 0.5480 - val_loss: 1.4543 - val_accuracy: 0.4830\n",
      "Epoch 434/500\n",
      "395/395 [==============================] - 49s 123ms/step - loss: 1.2862 - accuracy: 0.5406 - val_loss: 1.4817 - val_accuracy: 0.4741\n",
      "Epoch 435/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2828 - accuracy: 0.5491 - val_loss: 1.4736 - val_accuracy: 0.4779\n",
      "Epoch 436/500\n",
      "395/395 [==============================] - 48s 123ms/step - loss: 1.2816 - accuracy: 0.5458 - val_loss: 1.4731 - val_accuracy: 0.4842\n",
      "Epoch 437/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2792 - accuracy: 0.5498 - val_loss: 1.4066 - val_accuracy: 0.5195\n",
      "Epoch 438/500\n",
      "395/395 [==============================] - 48s 123ms/step - loss: 1.2741 - accuracy: 0.5448 - val_loss: 1.4206 - val_accuracy: 0.5107\n",
      "Epoch 439/500\n",
      "395/395 [==============================] - 48s 123ms/step - loss: 1.2783 - accuracy: 0.5491 - val_loss: 1.5052 - val_accuracy: 0.4666\n",
      "Epoch 440/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2708 - accuracy: 0.5532 - val_loss: 1.4333 - val_accuracy: 0.4905\n",
      "Epoch 441/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2683 - accuracy: 0.5528 - val_loss: 1.4282 - val_accuracy: 0.4981\n",
      "Epoch 442/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2645 - accuracy: 0.5474 - val_loss: 1.4757 - val_accuracy: 0.4767\n",
      "Epoch 443/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2566 - accuracy: 0.5571 - val_loss: 1.4444 - val_accuracy: 0.4830\n",
      "Epoch 444/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2724 - accuracy: 0.5469 - val_loss: 1.4618 - val_accuracy: 0.4968\n",
      "Epoch 445/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2635 - accuracy: 0.5539 - val_loss: 1.4874 - val_accuracy: 0.4691\n",
      "Epoch 446/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2629 - accuracy: 0.5537 - val_loss: 1.4067 - val_accuracy: 0.5032\n",
      "Epoch 447/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2566 - accuracy: 0.5526 - val_loss: 1.4161 - val_accuracy: 0.5032\n",
      "Epoch 448/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2597 - accuracy: 0.5594 - val_loss: 1.5868 - val_accuracy: 0.4451\n",
      "Epoch 449/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2630 - accuracy: 0.5510 - val_loss: 1.4689 - val_accuracy: 0.4905\n",
      "Epoch 450/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.2584 - accuracy: 0.5518 - val_loss: 1.4412 - val_accuracy: 0.4931\n",
      "Epoch 451/500\n",
      "395/395 [==============================] - 47s 120ms/step - loss: 1.2519 - accuracy: 0.5553 - val_loss: 1.4734 - val_accuracy: 0.4716\n",
      "Epoch 452/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2554 - accuracy: 0.5548 - val_loss: 1.4510 - val_accuracy: 0.4830\n",
      "Epoch 453/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2525 - accuracy: 0.5623 - val_loss: 1.4262 - val_accuracy: 0.5082\n",
      "Epoch 454/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2484 - accuracy: 0.5552 - val_loss: 1.4597 - val_accuracy: 0.4943\n",
      "Epoch 455/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2510 - accuracy: 0.5528 - val_loss: 1.4704 - val_accuracy: 0.4880\n",
      "Epoch 456/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2399 - accuracy: 0.5596 - val_loss: 1.4635 - val_accuracy: 0.4956\n",
      "Epoch 457/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2461 - accuracy: 0.5559 - val_loss: 1.4457 - val_accuracy: 0.4981\n",
      "Epoch 458/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2529 - accuracy: 0.5499 - val_loss: 1.5061 - val_accuracy: 0.4678\n",
      "Epoch 459/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2524 - accuracy: 0.5545 - val_loss: 1.4380 - val_accuracy: 0.5019\n",
      "Epoch 460/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2398 - accuracy: 0.5566 - val_loss: 1.4813 - val_accuracy: 0.4855\n",
      "Epoch 461/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2386 - accuracy: 0.5635 - val_loss: 1.4390 - val_accuracy: 0.5057\n",
      "Epoch 462/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2430 - accuracy: 0.5640 - val_loss: 1.4255 - val_accuracy: 0.5057\n",
      "Epoch 463/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2362 - accuracy: 0.5645 - val_loss: 1.4841 - val_accuracy: 0.4578\n",
      "Epoch 464/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2364 - accuracy: 0.5602 - val_loss: 1.5023 - val_accuracy: 0.4515\n",
      "Epoch 465/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2329 - accuracy: 0.5683 - val_loss: 1.5608 - val_accuracy: 0.4451\n",
      "Epoch 466/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2268 - accuracy: 0.5651 - val_loss: 1.4667 - val_accuracy: 0.4792\n",
      "Epoch 467/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2313 - accuracy: 0.5637 - val_loss: 1.5474 - val_accuracy: 0.4729\n",
      "Epoch 468/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2297 - accuracy: 0.5683 - val_loss: 1.4722 - val_accuracy: 0.4842\n",
      "Epoch 469/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.2306 - accuracy: 0.5659 - val_loss: 1.4327 - val_accuracy: 0.4943\n",
      "Epoch 470/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2269 - accuracy: 0.5651 - val_loss: 1.4758 - val_accuracy: 0.4741\n",
      "Epoch 471/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2195 - accuracy: 0.5675 - val_loss: 1.4682 - val_accuracy: 0.5107\n",
      "Epoch 472/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2236 - accuracy: 0.5675 - val_loss: 1.5621 - val_accuracy: 0.4540\n",
      "Epoch 473/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2129 - accuracy: 0.5694 - val_loss: 1.4854 - val_accuracy: 0.4855\n",
      "Epoch 474/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2225 - accuracy: 0.5639 - val_loss: 1.4603 - val_accuracy: 0.4880\n",
      "Epoch 475/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2258 - accuracy: 0.5635 - val_loss: 1.4297 - val_accuracy: 0.5082\n",
      "Epoch 476/500\n",
      "395/395 [==============================] - 39s 100ms/step - loss: 1.2117 - accuracy: 0.5705 - val_loss: 1.4556 - val_accuracy: 0.5006\n",
      "Epoch 477/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2218 - accuracy: 0.5734 - val_loss: 1.5559 - val_accuracy: 0.4641\n",
      "Epoch 478/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2118 - accuracy: 0.5802 - val_loss: 1.4994 - val_accuracy: 0.4729\n",
      "Epoch 479/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2108 - accuracy: 0.5734 - val_loss: 1.4670 - val_accuracy: 0.4805\n",
      "Epoch 480/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2147 - accuracy: 0.5715 - val_loss: 1.4265 - val_accuracy: 0.5132\n",
      "Epoch 481/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2035 - accuracy: 0.5737 - val_loss: 1.5019 - val_accuracy: 0.4880\n",
      "Epoch 482/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2058 - accuracy: 0.5754 - val_loss: 1.4617 - val_accuracy: 0.4817\n",
      "Epoch 483/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2089 - accuracy: 0.5743 - val_loss: 1.5017 - val_accuracy: 0.4855\n",
      "Epoch 484/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2074 - accuracy: 0.5735 - val_loss: 1.4779 - val_accuracy: 0.4893\n",
      "Epoch 485/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2005 - accuracy: 0.5789 - val_loss: 1.4561 - val_accuracy: 0.4893\n",
      "Epoch 486/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.1971 - accuracy: 0.5781 - val_loss: 1.5152 - val_accuracy: 0.4767\n",
      "Epoch 487/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.1956 - accuracy: 0.5811 - val_loss: 1.4727 - val_accuracy: 0.4905\n",
      "Epoch 488/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2005 - accuracy: 0.5724 - val_loss: 1.4280 - val_accuracy: 0.5006\n",
      "Epoch 489/500\n",
      "395/395 [==============================] - 40s 101ms/step - loss: 1.1943 - accuracy: 0.5778 - val_loss: 1.4831 - val_accuracy: 0.4918\n",
      "Epoch 490/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2016 - accuracy: 0.5758 - val_loss: 1.4748 - val_accuracy: 0.4905\n",
      "Epoch 491/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.3965 - accuracy: 0.4992 - val_loss: 1.4677 - val_accuracy: 0.4880\n",
      "Epoch 492/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2450 - accuracy: 0.5571 - val_loss: 1.4496 - val_accuracy: 0.4918\n",
      "Epoch 493/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2215 - accuracy: 0.5655 - val_loss: 1.5510 - val_accuracy: 0.4716\n",
      "Epoch 494/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2136 - accuracy: 0.5632 - val_loss: 1.5148 - val_accuracy: 0.4905\n",
      "Epoch 495/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2072 - accuracy: 0.5764 - val_loss: 1.4598 - val_accuracy: 0.4880\n",
      "Epoch 496/500\n",
      "395/395 [==============================] - 40s 100ms/step - loss: 1.2018 - accuracy: 0.5770 - val_loss: 1.4543 - val_accuracy: 0.5132\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 45s 113ms/step - loss: 1.1933 - accuracy: 0.5759 - val_loss: 1.4823 - val_accuracy: 0.4830\n",
      "Epoch 498/500\n",
      "395/395 [==============================] - 48s 122ms/step - loss: 1.1853 - accuracy: 0.5811 - val_loss: 1.5871 - val_accuracy: 0.4515\n",
      "Epoch 499/500\n",
      "395/395 [==============================] - 49s 123ms/step - loss: 1.1930 - accuracy: 0.5739 - val_loss: 1.5437 - val_accuracy: 0.4666\n",
      "Epoch 500/500\n",
      "395/395 [==============================] - 49s 124ms/step - loss: 1.1965 - accuracy: 0.5792 - val_loss: 1.5384 - val_accuracy: 0.4628\n",
      "CPU times: user 5h 36min 49s, sys: 14min 57s, total: 5h 51min 46s\n",
      "Wall time: 5h 50min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/GPU:0'):\n",
    "    history=model.fit(X_train,\n",
    "              y_train,\n",
    "              epochs=500,\n",
    "              batch_size=16,\n",
    "              validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the validation and training set results diverge when the model achieves about 45% accuracy over the validation set, just as with the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (test set)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.60      0.50        96\n",
      "           1       0.29      0.22      0.25        98\n",
      "           2       0.28      0.12      0.17       100\n",
      "           3       0.58      0.57      0.58       100\n",
      "           4       0.26      0.45      0.33       100\n",
      "           5       0.50      0.21      0.30       100\n",
      "           6       0.21      0.22      0.21       100\n",
      "           7       0.41      0.50      0.45       100\n",
      "\n",
      "    accuracy                           0.36       794\n",
      "   macro avg       0.37      0.36      0.35       794\n",
      "weighted avg       0.37      0.36      0.35       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make clear this is test set\n",
    "y_pred=model.predict_classes(X_test)\n",
    "print('Classification Report (test set)')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the set of:  \n",
    "* 8 classes\n",
    "* 1000 samples each class\n",
    "\n",
    "The CNN-LSTM model shows a modest improvement over both the CNN and LSTM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Accuracy(all classes) | Train Time |\n",
    "| --- | --- | --- |\n",
    "| CNN | .38 | 15m |\n",
    "| LSTM | .34 | 90m |\n",
    "| CNN-LSTM | .36 | 5m |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
