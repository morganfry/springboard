{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Springboard Data Science Track Capstone Project 1\n",
    "### Histopathologic Cancer Detection\n",
    "### by Morgan Fry\n",
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done the data wrangling and some exploratory data analysis we are going to  try to build a baseline image classification model based. We will try a logistic regression to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import sys\n",
    "import cv2\n",
    "import seaborn as snsb0811f6beb7d82331f7f0f40cd75af0820c5e02ebdadd8b8\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import scipy as sp\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from time import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "y_d=pickle.load(open(\"saved/y.p\",\"rb\"))\n",
    "X_d=pickle.load(open(\"saved/X.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize data into dataframes\n",
    "#to save computational time at this point, we'll use the cropped images\n",
    "X_crop_d={}\n",
    "\n",
    "for each in X_d.items():\n",
    "    X_crop_d.update({each[0]:each[1][31:63,31:63].flatten()})\n",
    "  #  X_v_d.update({each[0]:each[1].flatten()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_crop_df=pd.DataFrame.from_dict(X_crop_d,orient='index')\n",
    "#X_vect_df=pd.DataFrame.from_dict(X_vect_d,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 dataframes, one with cropped images, both with id's and labels\n",
    "Xy_crop_df=X_crop_df.merge(y_d,right_on='id',left_index=True)\n",
    "#Xy_df=X_vect_df.merge(y_d,right_on='id',left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244</td>\n",
       "      <td>243</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>245</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>249</td>\n",
       "      <td>245</td>\n",
       "      <td>248</td>\n",
       "      <td>247</td>\n",
       "      <td>243</td>\n",
       "      <td>245</td>\n",
       "      <td>244</td>\n",
       "      <td>240</td>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>254</td>\n",
       "      <td>250</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>234</td>\n",
       "      <td>231</td>\n",
       "      <td>233</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>248</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>174</td>\n",
       "      <td>187</td>\n",
       "      <td>195</td>\n",
       "      <td>162</td>\n",
       "      <td>189</td>\n",
       "      <td>177</td>\n",
       "      <td>148</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>226</td>\n",
       "      <td>168</td>\n",
       "      <td>160</td>\n",
       "      <td>183</td>\n",
       "      <td>199</td>\n",
       "      <td>193</td>\n",
       "      <td>212</td>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173</td>\n",
       "      <td>106</td>\n",
       "      <td>173</td>\n",
       "      <td>218</td>\n",
       "      <td>139</td>\n",
       "      <td>206</td>\n",
       "      <td>172</td>\n",
       "      <td>98</td>\n",
       "      <td>158</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>145</td>\n",
       "      <td>177</td>\n",
       "      <td>106</td>\n",
       "      <td>169</td>\n",
       "      <td>191</td>\n",
       "      <td>118</td>\n",
       "      <td>186</td>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>36</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>96</td>\n",
       "      <td>212</td>\n",
       "      <td>178</td>\n",
       "      <td>242</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>105</td>\n",
       "      <td>64</td>\n",
       "      <td>121</td>\n",
       "      <td>77</td>\n",
       "      <td>27</td>\n",
       "      <td>81</td>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3074 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  3064  3065  3066  \\\n",
       "0  244  243  245  245  247  248  245  247  248  244  ...   249   245   248   \n",
       "1  253  252  254  250  247  249  234  231  233  255  ...   249   249   249   \n",
       "2  184  174  187  195  162  189  177  148  174  173  ...   199   226   168   \n",
       "3  173  106  173  218  139  206  172   98  158  191  ...    85   145   177   \n",
       "4   74   36   66   82   39   96  212  178  242  119  ...    20    80   105   \n",
       "\n",
       "   3067  3068  3069  3070  3071                                        id  \\\n",
       "0   247   243   245   244   240  f38a6374c348f90b587e046aac6079959adf3835   \n",
       "1   249   249   248   250   250  c18f2d887b7ae4f6742ee445113fa1aef383ed77   \n",
       "2   160   183   199   193   212  755db6279dae599ebb4d39a9123cce439965282d   \n",
       "3   106   169   191   118   186  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08   \n",
       "4    64   121    77    27    81  068aba587a4950175d04c680d38943fd488d6a9d   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 3074 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy_crop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the dataset is organized we'll split it and scale it\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy_crop_df.iloc[:,:3071].values, \n",
    "                                              Xy_crop_df.label.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train) \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(n_jobs=-1)\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (train)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77     98161\n",
      "           1       0.68      0.53      0.60     66857\n",
      "\n",
      "    accuracy                           0.71    165018\n",
      "   macro avg       0.70      0.68      0.68    165018\n",
      "weighted avg       0.71      0.71      0.70    165018\n",
      "\n",
      "Classification Report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77     32747\n",
      "           1       0.67      0.52      0.59     22260\n",
      "\n",
      "    accuracy                           0.70     55007\n",
      "   macro avg       0.70      0.68      0.68     55007\n",
      "weighted avg       0.70      0.70      0.70     55007\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27027  5720]\n",
      " [10577 11683]]\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report (train)')\n",
    "print(classification_report(y_train,clf.predict(X_train)))\n",
    "print('Classification Report (test)')\n",
    "print(classification_report(y_test,clf.predict(X_test)))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple logistic regression does an inadequate job for this problem. We are looking to identify samples with cancerous cells in images. What measure shoul we be aiming for? There are a few factors to consider:\n",
    "* Both false negatives and false positives matter. \n",
    "More false positives among a population in which the positive condition is rare means that even with a high accuracy a positive result can still mean a low chance of the condition tested for. More false negatives are even more important as that can mean sick people do not get treatment they need.\n",
    "* There are about 50% more negative than positive samples in this dataset, so as you see above there is much better recall for negative samples than positive. \n",
    "\n",
    "Given these factors using the F1 score for the Positive case is the proper metric to judge the classifier by at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we can tell a few things:\n",
    "* The F1 score for Positive cases over the test set is .59, for Negatives .77. \n",
    "* Accordingly, the confusion matrix shows about twice as many false negatives (10577) as false positives (5720)\n",
    "* The numbers are all similar for the train and test set, indicating the model isn't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need a rather better model than this. We need to see scores of .95 or better for a classifier to be useful in this field. We might be able to eek out a little better results with tuning some of the parameters of the logistic regression, but ultimately we need to find a more robust strategy. Maybe a SVM or random forest or ultimately a neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
